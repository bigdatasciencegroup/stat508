---
title: "STAT 508 Project 1"
author: "Sebastian Bautista"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment='>')

library(ISLR)
library(GGally)
library(car)
library(leaps)
library(glmnet)
library(pls)
```

# 0. Introduction

For this project, we're looking at the College data set, aiming to predict the number of applications received by a college. 

# 1. Data

`College` is a cross-sectional data set where each observation is a US college from the 1995 issue of US News and World Report. Our response variable is `apps` and there are 17 other variables in the data. 

# 2. Analyses

1. *Examine the data using exploratory data analysis tools. Are there any features that would appear to jeopardize linear regression modeling? If so, address these issues before going any further.*

2. *Split the data into a training and a test set.*

3. *Using best subset selection, fit a least-squares regression model on the training set, and report the test error obtained.*

4. *Fit a ridge regression model on the training set, with lambda chosen by cross-validation. Report the test error obtained.*

5. *Repeat #4 with a lasso model instead of ridge regression, and report the test error obtained as well as the number of nonzero coefficient estimates.*

6. *Fit a PCR model on the training set, with M chosen by cross-validation. Report the test error as well as the value of M selected.*

7. *Repeat #6 with a PLS model instead of PCR.*

*Comment on the results obtained. What is the prediction accuracy? How do the different methods agree/disagree? Summarize your findings in a report, following the usual guidelines. Please pay special attention to your presentation, writing, and cohesiveness of analysis.* 


# 3. Plots and Tables

```{r}
# exploratory data analysis
df = College

# changing variable names to lower case
names(df) = tolower(names(df))
str(df)

# checking for missings
cat(sum(is.na(df)), 'missing values')
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# look at first few obs
head(df)
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# p.undergrad, f.undergrad, enroll, accept, apps are positive skewed (mean>med)
# our sample is 72.7% private schools and 27.3% public
summary(df)
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# trying a simple linear model
reg = lm(apps ~ ., data=df)
summary(reg)
# heteroskedasticity and non-normality in residuals but the fit is good overall
plot(reg, which=1)
cat('MSE:',mean(summary(reg)$residuals^2))
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
numdf = model.matrix(~., data=df)[,-1]
# positive outliers and skew for apps, accept, p.undergrad, books, and expend
boxplot(scale(numdf), las=2, main='College data set, scaled')
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# a lot of these pairs make sense that they would be highly collinear
# probably leaning towards feature selection because of this
# apps, our response, is highly correlated with accept, enroll, and f.undergrad
# apps, accept, enroll, and f.undergrad
ggcorr(numdf, label=T)
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# enroll and f.undergrad show high signs of multicollinearity
# accept, top10perc, and top25perc are also somewhat high
sort(vif(reg), decreasing=T)
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill

```{r}
# possible obs to drop
outlierTest(reg)
```
\begin{center}\textbf{Figure X}\end{center}
\hrulefill


```{r}
# BEST SUBSET SELECTION

# drop enroll and f.undergrad because of VIF
df$enroll = NULL
df$f.undergrad = NULL

# train-test split
set.seed(90210)
train = sample(1:nrow(df), nrow(df)/2)
test = (-train)

# number of predictors p
nvmax = length(names(df)) - 1

bss = regsubsets(apps ~ ., data=df[train,], nvmax=nvmax)

test.mat = model.matrix(apps ~ ., data=df[test,])

val.errors = rep(NA,nvmax)
for(i in 1:nvmax){
  coefi = coef(bss, id=i)
  pred = test.mat[,names(coefi)] %*% coefi
  val.errors[i] = mean((df$apps[test] - pred)^2)
}

num.vars = which.min(val.errors)
coef(bss, num.vars)
paste("The winning model contains", num.vars, "variables")
paste("The test set MSE for the model chosen by best subset selection is", round(val.errors[num.vars]))
```
\begin{center}\textbf{Figure X - Best subset selection}\end{center}
\hrulefill

```{r}
# RIDGE

X = model.matrix(apps ~ ., df)[,-1]
y = df$apps

Xtrain = X[train,]
Xtest = X[test,]
ytrain = y[train]
ytest = y[test]

lambda = 10^seq(10, -4, length=5000)

cv.ridge = cv.glmnet(Xtrain, ytrain, alpha=0, lambda=lambda)

ridge.lambda = cv.ridge$lambda.min

ridge = glmnet(Xtrain, ytrain, alpha=0, lambda=lambda)
ridge.yhat = predict(ridge, s=ridge.lambda, newx=Xtest)
ridge.test.mse = mean((ridge.yhat - ytest)^2)

ridge.full = glmnet(X, y, alpha=0)

# Refit on whole data set
print(predict(ridge.full, type='coefficients', s=ridge.lambda))
paste("The value of lambda that returns the smallest CV error for ridge is", round(ridge.lambda, 3))
paste("The test set MSE for ridge is", round(ridge.test.mse))
```
\begin{center}\textbf{Figure X - Ridge}\end{center}
\hrulefill

```{r}
# LASSO

cv.lasso = cv.glmnet(Xtrain, ytrain, alpha=1, lambda=lambda)

lasso.lambda = cv.lasso$lambda.min

lasso = glmnet(Xtrain, ytrain, alpha=1, lambda=lambda)
lasso.yhat = predict(lasso, s=lasso.lambda, newx=Xtest)
lasso.test.mse = mean((lasso.yhat - ytest)^2)

lasso.full = glmnet(X, y, alpha=1)

# Refit on whole data set
print(predict(lasso.full, type='coefficients', s=lasso.lambda))
paste("The value of lambda that yields the smallest CV error for lasso is", round(lasso.lambda, 3))
paste("The test set MSE for lasso is", round(lasso.test.mse))
```
\begin{center}\textbf{Figure X - Lasso}\end{center}
\hrulefill

```{r}
# PCR

cv.pcr = pcr(apps ~ ., data=df, subset=train, scale=T, validation='CV')

cverr = MSEP(cv.pcr)$val[1,,]
ncomp = (which.min(cverr) - 1)[[1]]

pcr.yhat = predict(cv.pcr, Xtest, ncomp=ncomp)
pcr.mse = mean((pcr.yhat - ytest)^2)

pcr.full = pcr(y~X, scale=T, ncomp=ncomp)

cat('Optimal number of principal components: ', ncomp)
cat('Test MSE for pcr: ', round(pcr.mse))
```
\begin{center}\textbf{Figure X - Principal Components Regression}\end{center}
\hrulefill

```{r}
# PLSR

cv.pls = plsr(apps ~ ., data=df, subset=train, scale=T, validation='CV')

cverr = MSEP(cv.pls)$val[1,,]
ncomp = (which.min(cverr) - 1)[[1]]

pls.yhat = predict(cv.pls, Xtest, ncomp=ncomp)
pls.mse = mean((pls.yhat - ytest)^2)

pls.full = plsr(y~X, scale=T, ncomp=ncomp)

cat('Optimal number of principal components: ', ncomp)
cat('Test MSE for pls: ', round(pls.mse))
```
\begin{center}\textbf{Figure X - Partial Least Squares Regression}\end{center}
\hrulefill

# 4. Conclusions

# 5. Appendix

```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```
