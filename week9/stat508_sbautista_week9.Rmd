---
title: "STAT 508 Data Analysis Assignment 9"
author: "Sebastian Bautista"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment='>', echo=F)
options(digits=2)

library(ISLR)
library(MASS)
df = Weekly
names(df) = tolower(names(df))
```

# 0. Introduction

This week, we're looking at a data set containing weekly percentage returns for the S&P 500 between 1990 and 2010. We aim to predict `Direction`, a dummy variable with two levels corresponding to downward and upward movement, using lagged returns and trading volume. 

I find that in this case, logistic regression and LDA perform identically well, and QDA performs poorly because it predicts an increase in the S&P 500 every week. I tried out a few models including interaction terms and higher order polynomials, but was unable to definitely improve the performance of the classifiers. A summary of all models tested can be found at the end of the plots/figures section in **Figure 6**.

# 1. Data

Our data set contains 1089 observations representing 47 weeks in 1990 and 52 weeks for each year between 1991 and 2010. The 9 variables in the data set represent the year, one- to five-week lags of percentage returns, the volume of shares traded (billions), the percentage return for the  present week, and a factor variable indicating positive or negative returns for the current week. All but the final variable are numeric. 44% of the data is labeled "Down" and 56% is labeled "Up". **Figure 1.1** shows the structure of the data.

# 2. Analyses

*1. Produce some numerical and graphical summaries. Do there appear to be any patterns?*

**Figures 1.2 and 1.3** show pairwise correlations in graphic and numeric form. The most obvious correlation is between `volume` and `year`, which merely tells us that more trades are made as time goes on, probably a result of the Internet and other lowered barriers to entry related to stock trading. 

*2. Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?*

**Figure 2.1** shows the results of fitting a logistic regression model to the full data set. The intercept and `lag2` are the only statistically significant variables. The positive intercept indicates that the S&P is more likely to go up than down, given that the other covariates are somehow 0. The positive coefficient on `lag2` tells us that a positive (negative) return in week *t-2* is associated with a positive (negative) return in the current week, week *t*. 

*3. Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.*

Using the values in the confusion matrix, I calculate accuracy, recall/sensitivity, specificity, and precision. Accuracy of 56% tells us that the model was correct 56% of the time - since 56% of our data is the positive class "Up", we could trivially achieve this exact level of accuracy by predicting that the S&P 500 increases every week.

Recall/sensitivity is calculated to be 92%. This means that this model was able to correctly identify about 557 of the 605 weeks in the full data set that had positive returns.

On the other hand, specificity is shown to be 11%, meaning that this model only correctly identified 53 of the 484 negative-return weeks in the full data set.

Precision (positive predictive value) of 56% means that, when the classifier predicted positive returns, it was correct 56% of the time (and incorrect 44% of the time).

All in all, this classifier has relatively high type II error (false negatives) and low type I error (false positives). In the context of this classification problem, that means this model is more likely to guess that a positive week is actually negative rather than the other way around. High recall means that it's good at picking out positive weeks, but low specificity and moderate precision respectively mean it's not great at picking out negative weeks and is sometimes wrong when it predicts a positive week.

*4. Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010).*

*5. Repeat step 4 using LDA.*

*6. Repeat step 4 using QDA.*

*7. Which of these methods appears to provide the best results on this data?*

*8. Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data.*

# 3. Plots and Tables

```{r}
str(df)
cat('\nPrevalence of each level of direction')
table(df$direction)/sum(table(df$direction))
```
\begin{center}\textbf{Figure 1.1 - Structure of Weekly data set}\end{center}
\hrulefill

```{r}
pairs(df[-9])
```
\begin{center}\textbf{Figure 1.2 - Pairwise correlation plots}\end{center}
\hrulefill

```{r}
cor(df[-9])
# high positive r between `volume` and `year` = more trades are made in later years
```
\begin{center}\textbf{Figure 1.3 - Correlation matrix}\end{center}
\hrulefill

```{r}
#*2. Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?*

formula = direction ~ lag1 + lag2 + lag3 + lag4 + lag5 + volume
logistic = glm(formula=formula, data=df, family=binomial)
summary(logistic)
# the intercept and lag2 are statistically significant
```
\begin{center}\textbf{Figure 2.1 - Logistic regression, full data}\end{center}
\hrulefill

```{r}
#*3. Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.*

cat('Results using formula: ')
print(formula)

logistic.probs = predict(logistic, type='response')
logistic.pred = rep("Down", nrow(df))
logistic.pred[logistic.probs > 0.5] = "Up"

cm = table(logistic.pred, df$direction)
cm

# do calculations here. accuracy, sensitivity(recall), specificity(true negative rate), precision(positive predictive value)
# accuracy 
# what percent of our predictions were right?
accuracy = (cm[2,2]+cm[1,1])/sum(cm)

# sensitivity (recall, true positive rate)
# of the positive class, how many did we correctly identify?
recall = cm[2,2]/sum(cm[,2])

# specificity (true negative rate)
# of the negative class, how many did we correctly identify?
specificity = cm[1,1]/sum(cm[,1])

# precision (positive predictive value)
# when we predicted the positive class, how often were we correct?
precision = cm[2,2]/sum(cm[2,])

cat('\nWhat percent of our predictions were right? \nAccuracy: ', accuracy)
cat('\n\nOf the positive class, how many did we correctly identify? \nRecall: ', recall)
cat('\n\nOf the negative class, how many did we correctly identify? \nSpecificity: ', specificity)
cat('\n\nWhen we predicted the positive class, how often were we correct? \nPrecision: ', precision)
```
\begin{center}\textbf{Figure 2.2 - Confusion matrix and rates, logistic, full data}\end{center}
\hrulefill

```{r}
#*4. Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010).*

train = (df$year < 2009)
df.test = df[!train,]
direction.test = df$direction[!train]

# fit logistic using training data, then predict on test data
formula = direction ~ lag2
logistic = glm(formula=formula, data=df, family=binomial, subset=train)

cm.logistic <- function(model){
  # given a fitted logistic model, predicts on the test set,
  # prints a confusion matrix,
  # then prints rates calculated from the values of the matrix
  
  model.probs = predict(model, df.test, type='response')
  yhat = rep('Down', nrow(df.test))
  yhat[model.probs > 0.5] = "Up"
  
  cm = table(yhat, direction.test)
  accuracy = (cm[2,2]+cm[1,1])/sum(cm)
  recall = cm[2,2]/sum(cm[,2])
  specificity = cm[1,1]/sum(cm[,1])
  precision = cm[2,2]/sum(cm[2,])
  
  cat('\n')
  print(cm)
  
  cat('\nAccuracy: ', accuracy)
  cat('\nRecall: ', recall)
  cat('\nSpecificity: ', specificity)
  cat('\nPrecision: ', precision)
}

cat('Logistic results for ')
print(formula)
cm.logistic(logistic)
```
\begin{center}\textbf{Figure 3.1 - Logistic test set results}\end{center}
\hrulefill

```{r}
#*5. Repeat step 4 using LDA.*

cm.calc <- function(model){
  # given a fitted model, predicts on the test set,
  # prints a confusion matrix,
  # then prints rates calculated from the values of the matrix
  
  model.probs = predict(model, df.test, type='response')
  yhat = model.probs$class
  
  cm = table(yhat, direction.test)
  accuracy = (cm[2,2]+cm[1,1])/sum(cm)
  recall = cm[2,2]/sum(cm[,2])
  specificity = cm[1,1]/sum(cm[,1])
  precision = cm[2,2]/sum(cm[2,])
  cat('\n')
  print(cm)
  
  cat('\nAccuracy: ', accuracy)
  cat('\nRecall: ', recall)
  cat('\nSpecificity: ', specificity)
  cat('\nPrecision: ', precision)
}

formula = direction ~ lag2
lda = lda(formula=formula, data=df, subset=train)
cat('LDA results for ')
print(formula)
cm.calc(lda)
```
\begin{center}\textbf{Figure 3.2 - LDA test set results}\end{center}
\hrulefill

```{r}
#*6. Repeat step 4 using QDA.*

formula = direction ~ lag2
qda = qda(formula=formula, data=df, subset=train)
cat('QDA results for ')
print(formula)
cm.calc(qda)
```
\begin{center}\textbf{Figure 3.3 - QDA test set results}\end{center}
\hrulefill

```{r}
#*8. Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data.*

formula = direction ~ (.-today)^2
logistic.int = glm(formula=formula, data=df, family=binomial, subset=train)
cat('Logistic results for ')
print(formula)
cm.logistic(logistic.int)
```
\begin{center}\textbf{Figure 4.1 - Logistic with interactions}\end{center}
\hrulefill

```{r}
formula = direction ~ (.-today)^2
lda.int = lda(formula=formula, data=df, subset=train)
cat('LDA results for ')
print(formula)
cm.calc(lda.int)
```
\begin{center}\textbf{Figure 4.2 - LDA with interactions}\end{center}
\hrulefill

```{r}
formula = direction ~ (.-today)^2
qda.int = qda(formula=formula, data=df, subset=train)
cat('QDA results for ')
print(formula)
cm.calc(qda.int)
```
\begin{center}\textbf{Figure 4.3 - QDA with interactions}\end{center}
\hrulefill

```{r}
formula = direction ~ lag2 + lag2^2 + lag2^3 
logistic.final = glm(formula=formula, data=df, family=binomial, subset=train)
cat('Logistic results for ')
print(formula)
cm.logistic(logistic.final)
```
\begin{center}\textbf{Figure 5.1 - Logistic with higher order terms}\end{center}
\hrulefill

```{r}
formula = direction ~ lag2 + lag2^2 + lag2^3 
lda.final = lda(formula=formula, data=df, subset=train)
cat('LDA results for ')
print(formula)
cm.calc(lda.final)
```
\begin{center}\textbf{Figure 5.2 - LDA with higher order terms}\end{center}
\hrulefill

```{r}
formula = direction ~ lag2 + lag2^2 + lag2^3
qda.final = qda(formula=formula, data=df, subset=train)
cat('QDA results for ')
print(formula)
cm.calc(qda.final)
```
\begin{center}\textbf{Figure 5.3 - QDA with interactions}\end{center}
\hrulefill

|                    | Logistic(lag2) | LDA(lag2) | QDA(lag2) | Logistic.int | LDA.int | QDA.int |
|--------------------|----------------|-----------|-----------|--------------|---------|---------|
| accuracy           | 62%            | 62%       | 59%       | 57%          | 58%     | 48%     |
| recall/sensitivity | 92%            | 92%       | 100%      | 59%          | 62%     | 36%     |
| specificity        | 21%            | 21%       | 0%        | 53%          | 51%     | 65%     |
| precision          | 62%            | 62%       | 59%       | 64%          | 64%     | 59%     |

\begin{center}\textbf{Figure 6 - Summary of calculated rates}\end{center}
\hrulefill

# 4. Conclusions

# 5. Appendix

```{r ref.label=knitr::all_labels(), echo=T, eval=F}
```